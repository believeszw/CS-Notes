# 音视频基础知识-时间戳的理解

## 问题背景：

凡是和流媒体和音视频打交道，时间戳基本是一个必须深刻理解的概念。你会在各种各样的传输协议和封装格式中看到这个东西，而且表现形式还不一样。其次这个概念会涉及到音视频播放的同步问题，也会影响音视频播放的控制问题。前者说的是音画同步，后者说的是类似快进，随机点播放等。如果要理解好这个概念，需要掌握下面几个名词的含义。

## 基本概念：

* **采样率**

音视频现在采用的数字编码方法，简单说就是把音视频这种波形和图像进行采集，量化，编码，传输，解码。所以采样率就是每秒钟抽取图像或者声波幅度样本的次数。**比如音频采样率 8k,就是表示把波形进行每秒 8000 次采样。**

我们看到一秒的采样频率其实挺大的，至于这个值是多少合理，其实无论视频还是音频都和人的视觉特征和听觉特征有关系。

对于人的视觉而言，只要 1 秒钟播放的视频达到 25 帧以上，我们就看到了连续的图像即为视频。如果低于这个值，我们人眼就能感觉出来卡顿。

对于人的听觉而言，正常的听觉频率范围在 20Hz-20kHz,根据奎斯特采样理论，为了保证音频不失真，我们的采样频率应该在 40kHz 左右。为什么采样率不是越高越好呢，因为采样率越高意味着你传输的数据量越多，这样给编码和传输都带了极大的负担，成本也是个重要考虑因素。

* **帧率**

帧率就是每秒显示的帧数，比如 30fps 就是 1 秒显示 30 帧图像。但是对于音频可能理解帧率不太好理解，这有点抽象。对于音频，不同的编码方式比如 AAC 和 mp3 分别就规定 1024 采样 sample，mp3 每帧为 1152 采样，如果一个采样用一个字节表示，那就是 1024 字节 AAC 编码音频为一帧，1152 字节为 MP3 编码方式的音频一帧。

* **时间戳单位**

前面我们提到采样率，感觉到采样率是个很大的单位，一般标准的音频 AAC 采样率达到了 44kHz,视频采样率也规定在 90000Hz.所以我们衡量时间的单位不能再是秒，毫秒这种真实的时间单位，我们的单位应该转换为采样率，也就是一个采样的时间为音视频的时间单位，这就是时间戳的真实值。当我们要播放和控制时，我们再将时间戳根据采样率转换为真实的时间即可。

一句话，时间戳不是真实的时间是采样次数。比如时间戳是 160，我们不能认为是 160 秒或者 160 毫秒，应该是 160 个采样。**要换算真实时间，我们必须知道采样率，比如 8000，那么说明 1 秒被划分成 8000 分之一，如果你要明确 160 个采样占用的时间，则 160*(1/8000) 即可，即 20 毫秒。**

* **时间戳增量**

就是一帧图像和另外一帧图像之间的时间戳差值，或者一帧音频和一帧音频的时间戳差值。同理时间戳增量也是采样个数的差值不是真实时间差值，还是要根据采样率才能换算成真实时间。

所以对于视频和音频的时间戳计算要一定明确帧率是多少，采样率是多少。

> 比如视频而言，帧率 25，那么对于 90000 的采样率来说，一帧占用的采样数就是 90000/25 也就是 3600，说明每帧图像的时间戳增量应该是 3600，换算成实际时间就是 3600*（1/90000）= 0.04 秒 = 40 毫秒，这也和 1/25 = 0.04 秒 = 40 毫秒一致。

> 对于 AAC 音频，一帧 1024 个采样，采样频率是 44kHz,所以一帧的播放时间应该是 1024*（1/44100）= 0.0232 秒 = 23.22 毫秒。

## 同步方法：

上面说了时间戳重要的功能就是来为了音视频的同步，那么这个时间戳到底是如何让音视频同步的呢？

播放器本地需要建立一个系统时钟，这个时钟一般是根据 CPU 时间计算出来的，当播放开始时时钟时间为 0，时间戳决定了一帧解码和渲染的时刻。当播放开始，时钟时间会进行增加，播放器会用系统时钟和当前视频和音频的时间戳进行比较，如果音视频的时间戳小于当前系统时钟，那么就要理解解码和渲染播放。

可以看到播放能否准确进行需要编码器打的时间戳必须精确，同时播放器端的系统时钟也精确，因为播放时要基于时间戳和这个系统时钟对数据流进行控制，也就是对数据块要根据时间戳来采取不同的处理方法。实际无论编码器还是本地播放器都不能非常精确，所以我们说固定帧率 25，也有可能编码器一遍打 24 帧的现象出现。为了解决这个累计误差问题，一般我们需要在播放端有一套反馈机制，能够消除这种误差。**其实，同步是一个动态的过程，是一个有人等待、有人追赶的过程。同步只是暂时的，而不同步才是常态。人们总是在同步的水平线上振荡波动，但不会偏离这条基线太远。**

## PTS 和 DTS：

上面通过介绍基本概念就是为了引出实际使用过程中时间戳的表现形式 PTS 和 DTS.

其中 DTS 就是 Decoding Time Stamp 即解码时间戳，这个时间戳的意义告诉播放器该在什么时候解码这一帧的数据；

PTS 即 Presentation TimeStamp 即显示时间戳，这个时间戳用来告诉播放器在什么时候显示这一帧的数据。

虽然这两个时间戳都是为了指导播放端的行为，但是他们都是由编码器生成的。正常情况下，我们一般解码出来一帧后，就需要立即进行播放，至于什么时候解码和什么时候播放，这个用一个时间戳来决定就可以，为啥现在引入了两个时间戳？当然这里说的 DTS 和 PTS 都是对视频而言的，**因为视频而言才会用两个时间戳**，音频还是用一个时间戳。换句话说播放器到了音频的时间戳就立即解码和播放，中间也不能有什么延时。**视频之所以比较复杂是因为你视频存在三种类型的帧，I P B.**

I 帧：帧内编码帧，又称为 intra picture. I 帧通常是每个 GOP 的第一个帧，采用的帧内压缩，经过适度压缩，作为随机访问的参考点，可以独立不依赖任何帧进行解码和显示。数据量最大，可以将其看为一张压缩的图像。

P 帧：前向预测编码帧，又称为 prdictive frame，通过充分将低于图像序列中前面已经编码帧的时间冗余信息来压缩传输数据的编码图像，其采用了帧间预测技术来进行编码。

B 帧：则是双向预测内插编码帧，又称为 bi-directionalinterpolated frame，相比较 P 帧依赖前面的帧还依赖后面的P帧进行利用帧间的冗余信息来压缩数据。

> 通过上面的比较，帧的压缩率 B 帧 > P 帧 > I 帧，数据量则刚好相反。

如果没有 B 帧，假设传输的视频帧是 I  P  P  P，那我们就根据每个帧的时间戳进行解码和显示即可，因为后面帧的时间戳总是大于前面的时间戳，我们用一个时间戳即可。但是有了 B 帧则解码和显示变得复杂起来。

1. 我们实际应该展示帧的顺序是: I B B P 帧解码后的顺序;

2. 但实际上，这些帧到达后，我们根据 I 帧和 B 帧的特点，实际在缓存的顺序为: I P B B;

3. 实际解码的顺序：1 4 2 3;

4. 最终展示的顺序是：1 2 3 4;

即先播放 I 帧，然后第一个 B 帧，第二个 B 帧，最后是 P 帧。

**综上我们看到上面的帧，解码顺序和播放显示顺序是不一致的，为了控制他们到底应该是什么时候解码，什么时候播放，则我们建立了 DTS 和 PTS 的概念。注意的是解码后的帧则只有 PTS 概念，未解码的帧才有 DTS 和 PTS 的概念。**

> 对于 I 帧则 PTS = DTS，P 帧的 PTS > DTS，B 帧 PTS < DTS。当然这里的大于和小于是相对 BP 帧而言。时间戳小则意味着先解码或者先显示，值越大意味着后处理。
